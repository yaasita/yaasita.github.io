<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>net on # cd ~yaasita</title>
    <link>https://yaasita.github.io/categories/net/</link>
    <description>Recent content in net on # cd ~yaasita</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Tue, 01 Mar 2022 02:34:41 +0900</lastBuildDate><atom:link href="https://yaasita.github.io/categories/net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>linuxのipv6一時アドレス2</title>
      <link>https://yaasita.github.io/2022/03/01/ipv6-tmpaddr/</link>
      <pubDate>Tue, 01 Mar 2022 02:34:41 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2022/03/01/ipv6-tmpaddr/</guid>
      <description>linuxでipv6一時アドレス使う時に設定するカーネルパラメータ
net.ipv6.conf.xxx.temp_prefered_lft = 86400 net.ipv6.conf.xxx.temp_valid_lft = 604800  これの意味は、上記のようにデフォルトの設定86400(1日), 604800(7日)だった場合
xxxインターフェイスにIPv6-1という一時アドレスが付いていたとする
IPv6-1作成してから24時間後にIPv6-2という新しい一時アドレスを取得する
取得後はIPv6-2のアドレスを使用して通信をするようになる
使わなくなったIPv6-1アドレスも7日間は有効なので受信することは可能
という仕組み
つまり、最大で7アドレスになるということ
1日目: IPv6-1
2日目: IPv6-1, IPv6-2
3日目: IPv6-1, IPv6-2, IPv6-3,
という風に増えていく
前回</description>
    </item>
    
    <item>
      <title>Linuxでipv6の一時アドレス</title>
      <link>https://yaasita.github.io/2022/02/26/ipv6-tempaddr/</link>
      <pubDate>Sat, 26 Feb 2022 23:16:10 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2022/02/26/ipv6-tempaddr/</guid>
      <description>systemd-networkdの設定にIPv6PrivacyExtensions足せばOK
(対応するカーネルパラメータ net.ipv6.conf.xxx.use_tempaddr は自動的に設定される)
[Network] Address=192.168.0.2/24 Gateway=192.168.0.1 IPv6PrivacyExtensions=yes  temp_valid_lft
と
temp_prefered_lft
については sysctlで設定すること
参考リンク
 https://wiki.archlinux.jp/index.php/IPv6 http://dr.slump.jp/IPv6/rfc3041/ https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt  </description>
    </item>
    
    <item>
      <title>ipv4/ipv6確認サイト</title>
      <link>https://yaasita.github.io/2022/02/23/ipv4-ipv6/</link>
      <pubDate>Wed, 23 Feb 2022 15:25:52 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2022/02/23/ipv4-ipv6/</guid>
      <description>自分のIPv4/IPv6アドレスを確認するサイトを作った
ipv4専用
https://ipv4.cloud.yaasita.net/
ipv6専用
https://ipv6.cloud.yaasita.net/
ipv4/ipv6両対応(どちらのIPが優先されるか確認用)
https://ipv46.cloud.yaasita.net/</description>
    </item>
    
    <item>
      <title>SMTP-TLSRPTのチェック</title>
      <link>https://yaasita.github.io/2022/02/12/tls-report-check/</link>
      <pubDate>Sat, 12 Feb 2022 01:24:48 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2022/02/12/tls-report-check/</guid>
      <description>SMTP-TLSRPTをチェックしてtotal-failure-session-countがゼロより大きいかチェックするスクリプト
(対象はGoogleから貰うレポート)
 こんな感じでメールがあるディレクトリを指定する
./index.js ~/Maildir/cur/  </description>
    </item>
    
    <item>
      <title>bridgeインターフェイスのMACアドレス</title>
      <link>https://yaasita.github.io/2021/10/10/machine-id/</link>
      <pubDate>Sun, 10 Oct 2021 05:52:16 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2021/10/10/machine-id/</guid>
      <description>KVMを使ったVM内でブリッジインターフェイス作ってそのVMをコピーしたらMACアドレスが重複して通信不能になった
(/etc/systemd/network/にはこんな感じでbridge作る)
https://gist.github.com/yaasita/d527b48f54b0e23c3097a9c69239d534
どうやらこれ、machine-idから作られてるみたいで、VMコピーしたらmachine-id変えた方が良いぽいね
rm /etc/machine-id /var/lib/dbus/machine-id dbus-uuidgen --ensure systemd-machine-id-setup  </description>
    </item>
    
    <item>
      <title>tumblrのテキスト情報を取得</title>
      <link>https://yaasita.github.io/2021/05/25/tumblr-metadata/</link>
      <pubDate>Tue, 25 May 2021 00:53:51 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2021/05/25/tumblr-metadata/</guid>
      <description>tumblrの検索だと、上手く引っかからない事が多いので
テキストデータはローカルに保存することにした
最初の投稿から何番目を指定することで、ディレクトリの年別ディレクトリに保存します
実行例
./get-tumblr-text.pl --tumblr_id yaasita --save_dir /tmp/ 1234   こんな感じで適度にsleep入れて取得してます
#!/bin/bash set -eux save_file=/tmp/save_num already_get_number=$(cat $save_file) for ((i=$already_get_number; i &amp;lt; $already_get_number + 100; i++));do ./get-tumblr-text.pl --tumblr_id yaasita --save_dir /tmp/ $i sleep 1 done echo $i &amp;gt; $save_file  </description>
    </item>
    
    <item>
      <title>GKEでGCSバックエンドと併用する時</title>
      <link>https://yaasita.github.io/2021/02/25/gke-neg/</link>
      <pubDate>Thu, 25 Feb 2021 02:26:18 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2021/02/25/gke-neg/</guid>
      <description>よくあるこんな構成
staticなHTML/CSSはGCSから、API部分はGKEからみたいな構成
 +---&amp;gt; GCS | ---&amp;gt; GCLB ---+ | +---&amp;gt; k8s(GKE)  これ、GCLB部分をingressにするのが良いんだけど、現状バックエンドサービスにGCSを登録できない
1.19ならできるぽいがなんか上手く行かなかったので
とりあえず、今の機能でやるなら、
NEGを作って、そこをGCLBのバックエンドサービスに登録する
https://cloud.google.com/kubernetes-engine/docs/how-to/standalone-neg
厳密な事を言うと、nodeportもバックエンドサービスに登録できるが、こっちはノードの増減によりエンドポイントが変わってしまうので不適
公式ドキュメント通りだけどこんな感じで作る
 あとはGCSにWebサイトの設定と、GCLBの設定すればOK</description>
    </item>
    
    <item>
      <title>postfixのReceived headerを隠す</title>
      <link>https://yaasita.github.io/2020/12/06/postfix-received-header/</link>
      <pubDate>Sun, 06 Dec 2020 01:11:10 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/12/06/postfix-received-header/</guid>
      <description>この回答通りなんだけど
一応補足とか
自分の環境だと、送信メールサーバーがセカンダリメールサーバーと兼任している
以下のように設定した
/etc/postfix/master.cf
smtps inet n - n - - smtpd -o syslog_name=postfix/smtps -o smtpd_tls_wrappermode=yes -o smtpd_sasl_auth_enable=yes -o smtpd_reject_unlisted_recipient=no -o smtpd_client_restrictions=$mua_client_restrictions -o smtpd_helo_restrictions=$mua_helo_restrictions -o smtpd_sender_restrictions=$mua_sender_restrictions -o smtpd_recipient_restrictions= -o smtpd_relay_restrictions=permit_sasl_authenticated,reject -o milter_macro_daemon_name=ORIGINATING -o cleanup_service_name=smtpscleanup smtpscleanup unix n - y - 0 cleanup -o header_checks=regexp:/etc/postfix/header_checks  /etc/postfix/header_checks
/^Received:.*/ IGNORE  最初はsmtp_header_checksをmain.cfに書けば良いかなーと思ったんだけど、
これだと外から入ってきたメール(後にプライマリサーバーにrelayされる)も一律削除されてしまうので都合が悪かった</description>
    </item>
    
    <item>
      <title>AWSのt4gインスタンスを試す</title>
      <link>https://yaasita.github.io/2020/11/05/t4g-instance/</link>
      <pubDate>Thu, 05 Nov 2020 02:58:38 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/11/05/t4g-instance/</guid>
      <description>新しくt4gインスタンスが出たみたいなので試してみた
cpuminer アルゴリズム=lyra2rev2 で測定
   name cpu memory hashrate(kH/s)     自宅PC Core i5-4460 3.20GHz 4コア 16G 384   ノートPC LB-C110B Celeron 1037U 1.80GHz 2コア 8G 79   t4g.micro (CPUクレジットあり) ARM CPU 2コア 1G 233   t4g.micro (CPUクレジットなし) ARM CPU 2コア 1G 24   aws lightsail (t2.nano, CPUクレジットあり) Xeon E5-2676 v3 2.40GHz 1コア 512M 81   aws lightsail (t2.nano, CPUクレジットなし) Xeon E5-2676 v3 2.</description>
    </item>
    
    <item>
      <title>Google Domainsを使ってみた</title>
      <link>https://yaasita.github.io/2020/06/03/google-domains/</link>
      <pubDate>Wed, 03 Jun 2020 02:59:51 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/06/03/google-domains/</guid>
      <description>自分のドメインを
Value Domainから Google Domains へ移管してみた
感想
 .net, .com 等は安い .jp は高い whois 代行は標準サービス 標準の権威DNSサーバーは微妙  GCPのGoogle Cloud DNSが使えるわけではない APIでの更新も難しそう HTTPリダイレクトの機能がついてるのは嬉しい ダイナミックDNSはある DNSSECは簡単にできそう SSHFPレコードを設定できる    まとめ
みんな使うと良いと思います</description>
    </item>
    
    <item>
      <title>DoHを試す</title>
      <link>https://yaasita.github.io/2020/05/10/doh/</link>
      <pubDate>Sun, 10 May 2020 03:22:35 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/05/10/doh/</guid>
      <description>DNS over HTTPSを試す
こんな構成で作る
Nginx -&amp;gt; doh-httpproxy -&amp;gt; systemd-resolved  インストール
doh-proxy pip3でインストールすればOK
pip3 install doh-proxy  以下のような設定でserviceを作る
/etc/systemd/system/doh-httpproxy.service
[Unit] Description=doh-httpproxy After=nginx.service [Install] WantedBy=multi-user.target [Service] ExecStart=/usr/local/bin/doh-httpproxy --upstream-resolver=127.0.0.53 --port 8080 --listen-address 127.0.0.1 Nginx側設定例
server { listen 443 ssl http2; server_name doh.example.net; ssl_certificate /etc/letsencrypt/live/doh.example.net/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/doh.example.net/privkey.pem; location /dns-query { proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; } }  確認
curl --doh-url https://doh.example.net/dns-query google.co.jp  </description>
    </item>
    
    <item>
      <title>BigQueryのカラムタイプ変更</title>
      <link>https://yaasita.github.io/2020/05/09/bigquery-type-change/</link>
      <pubDate>Sat, 09 May 2020 04:42:51 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/05/09/bigquery-type-change/</guid>
      <description>BigQueryのカラム変更はREQUIREDをNULLABLEにする以外は出来ません
テーブル スキーマの手動変更
作り直すしかないんですが、分割テーブルだともう一手間必要ですよという話
例えば以下のように分割テーブルを作るとします
bq mk --dataset test bq mk --table \ --time_partitioning_type DAY \ test.first  データを投入
echo -e &amp;quot;1\thoge&amp;quot; &amp;gt; /tmp/data.tsv echo -e &amp;quot;2\thuga&amp;quot; &amp;gt;&amp;gt; /tmp/data.tsv echo -e &amp;quot;3\tabcd&amp;quot; &amp;gt;&amp;gt; /tmp/data.tsv bq load --source_format=CSV --field_delimiter=&amp;quot;\t&amp;quot; \ &#39;test.first$20200501&#39; /tmp/data.tsv id:NUMERIC,description:STRING bq load --source_format=CSV --field_delimiter=&amp;quot;\t&amp;quot; \ &#39;test.first$20200502&#39; /tmp/data.tsv id:NUMERIC,description:STRING  取り込み時間別に分割されているのが分かります
echo &amp;quot;#standardSQL&amp;quot; &amp;gt; /tmp/query.sql echo &#39;select _PARTITIONTIME as pt, count(*) as count from test.first group by _PARTITIONTIME order by pt;&#39; &amp;gt;&amp;gt; /tmp/query.</description>
    </item>
    
    <item>
      <title>express.jsでpostのrawBodyを取得</title>
      <link>https://yaasita.github.io/2020/04/28/rawpostdata/</link>
      <pubDate>Tue, 28 Apr 2020 01:00:16 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/04/28/rawpostdata/</guid>
      <description>multipart/form-dataでPOSTされた奴を、処理するCloud functionsを書いてて必要になったので
 呼び出し側はこんな感じでやってる
 </description>
    </item>
    
    <item>
      <title>Github Pagesになってるリポジトリをチェック</title>
      <link>https://yaasita.github.io/2020/01/07/check-github-pages/</link>
      <pubDate>Tue, 07 Jan 2020 18:55:03 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/01/07/check-github-pages/</guid>
      <description>どのリポジトリがGithub Pagesの設定がされているか？
調べたくなったので・・・
Github pagesの設定されてるリポジトリ一覧を簡単に確認できればいいのに・・・
 </description>
    </item>
    
    <item>
      <title>GCPの外部IPアドレスが有料になる件</title>
      <link>https://yaasita.github.io/2020/01/06/gcp-ex-ip/</link>
      <pubDate>Mon, 06 Jan 2020 23:06:41 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2020/01/06/gcp-ex-ip/</guid>
      <description>外部IPが有料になりそうだからどうしようかという話
一部では無料範囲内なら課金されないみたいな書き方もされてるけど、今月の請求には不穏な項目がある
Credit External IPs will not be charged until April 1, 2020.  
んで、外部IPを無しにして、gcloud compute ssh で繋げるのは良いんだけど、外部IPが無いと外と通信できないからapt installもできない。。。。
あと、上記コマンドはsshポートを解放してないと駄目ぽい（正確にはIAPからのアクセスを許可すれば良いだけぽいが）
とりあえず課金されてから考えるか・・・
参考リンク  外部IPを持たないGCEインスタンスでweb開発 GCP/GCE の固定グローバルIPアドレス、2020年より有料化   function callback(data){ var photos = data.response.posts[0].photos; document.getElementById(&#34;tumblr-img&#34;).parentNode.href = photos[0].original_size.url; document.getElementById(&#34;tumblr-img&#34;).src = photos[0].original_size.url; }   </description>
    </item>
    
    <item>
      <title>GCP Cloud Functions内からサービスアカウントのtoken取る</title>
      <link>https://yaasita.github.io/2019/12/08/service-account-in-cf/</link>
      <pubDate>Sun, 08 Dec 2019 05:12:12 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2019/12/08/service-account-in-cf/</guid>
      <description>Cloud Functionsからサービスアカウントのアクセストークンをどうやって取るの？と疑問に思ったので調べた
Google Compute Engineと同じ取り方でOK
&amp;quot;use strict&amp;quot;; const fetch = require(&amp;quot;node-fetch&amp;quot;); exports.handler = async (req, res) =&amp;gt; { const url = &amp;quot;http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/&amp;quot; + &amp;quot;[サービスアカウント名]/token&amp;quot;; const result = await fetch(url, { method: &amp;quot;GET&amp;quot;, headers: { &amp;quot;Metadata-Flavor&amp;quot;: &amp;quot;Google&amp;quot; } }); const token = await result.text(); console.log(token); res.status(200).send(&amp;quot;OK&amp;quot;); };  なんでドキュメントにも書いてある今更な事を書くかというと日本語ドキュメントには見出しが無いんですよね。。。。

まだ翻訳終わってないならまだしも（本当は英文のままで良いからタイトルくらいは残してほしいが) &amp;ldquo;Function Identity&amp;quot;とかクリックするとちゃんと日本語版あるんですよね
なんかメニューがバグってるのかな・・・
とりあえず英語版から探すのをオススメします&amp;hellip;
参考リンク
 関数ID Compute Metadata Server   function callback(data){ var photos = data.response.posts[0].photos; document.getElementById(&#34;tumblr-img&#34;).parentNode.href = photos[0].</description>
    </item>
    
    <item>
      <title>ビリビリ動画とcrunchyrollのIP制限をGCPで検証</title>
      <link>https://yaasita.github.io/2019/09/14/anime-ip-block/</link>
      <pubDate>Sat, 14 Sep 2019 22:21:43 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2019/09/14/anime-ip-block/</guid>
      <description>bilibili動画とcrunchyrollのIP制限はどんな感じなのか
GCPの各リージョンからアクセスして試してみる
rttは自宅から該当サーバーまでのpingしたときの平均値
なのでISPによって全然違うと思うので参考値ということで
   region bilibili crunchyroll rtt(ms)     asia-east1 (台湾) ng ok 60.149   asia-east2 (香港) ng ok 76.986   asia-northeast1 (東京) ng ok 29.624   asia-northeast2 (大阪) ng ok 37.401   asia-south1 (ムンバイ) ng ok 144.055   asia-southeast1 (シンガポール) ng ok 89.755   australia-southeast1 (シドニー) ng ok 122.193   europe-north1 (フィンランド) ng ok 256.714   europe-west1 (ベルギー) ng ok 229.</description>
    </item>
    
    <item>
      <title>例のS3署名バージョン2について</title>
      <link>https://yaasita.github.io/2019/06/25/s3v2/</link>
      <pubDate>Tue, 25 Jun 2019 00:31:08 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2019/06/25/s3v2/</guid>
      <description>AWS S3の署名バージョン騒動
大丈夫ぽいけど一応調べた時につかったスクリプト
CloudTrailでログを有効化してからお使いください
 </description>
    </item>
    
    <item>
      <title>Cloud Runがすごく良い</title>
      <link>https://yaasita.github.io/2019/05/29/cloud-run/</link>
      <pubDate>Wed, 29 May 2019 21:42:23 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2019/05/29/cloud-run/</guid>
      <description>GCPのCloud Runがめっちゃ便利
覚えなきゃいけないルールは2つ
 Dockerにする事 環境変数 $PORT のポート番号でlistenしてレスポンスを返す事  これだけ
コマンドとかはこの辺見ればすぐできると思います
あと、Chunked Transferみたいな仕組みで進捗を返すみたいなAPIは難しいかもしれない
以下のようなプログラムでちょっとずつレスポンス返しても、バッファリングされてるみたいで、最後ドバっと返ってきた
 </description>
    </item>
    
    <item>
      <title>AlwaysOnSSL終了のお知らせ</title>
      <link>https://yaasita.github.io/2019/02/28/alwaysonssl/</link>
      <pubDate>Thu, 28 Feb 2019 01:44:13 +0900</pubDate>
      
      <guid>https://yaasita.github.io/2019/02/28/alwaysonssl/</guid>
      <description>無料のSSL証明書AlwaysOnSSLがセキュリティ問題を指摘されてシャットダウンしたぽい
AlwaysOnSSL web security issues
S/MIME手に入るので良かったんだけどなぁ・・・
前回</description>
    </item>
    
  </channel>
</rss>
